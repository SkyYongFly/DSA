#### 1. 开篇废话
##### 1.1 干了这碗鸡汤
**基础知识就像是一座大楼的地基，它决定了我们的技术高度。**

**人生路上，我们会遇到很多的坎。跨过去，你就可以成长，跨不过去就是困难和停滞。而在后面很长的一段时间里，你都需要为这个困难买单。**

##### 1.2 为什么学习数据结构与算法
* 掌握基础知识，便于运用
* 方便阅读框架源码，理解背后的设计思想
* 基础架构研发
* 建立时间复杂度、空间复杂度意识，写出高质量代码
 
##### 1.3 如何学习？
######  1）基本概念
* 数据结构：一组数据的存储结构
* 算法：操作数据的一组方法
######  2）相辅相成
数据结构是为算法服务的，算法要作用在特定的数据结构之上。

数据结构是静态的，只是组织数据的一种方式，如果不在其基础上操作，构建算法，孤立存在的数据结构是没用的。

数据结构和算法解决的是如何更省、更快地存储和处理数据的问题。

一个考量效率和资源消耗的方法，这就是复杂度分析方法，需要考虑：
时间复杂度、空间复杂度。
######  3) 基本内容
![913e0ababe43a2d57267df5c5f0832a7](数据结构与算法.resources/970F2600-54EF-4A17-B978-40C4EE39E47D.jpg)
######  4）重点内容
* 10 个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树；
* 10 个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。
######  5）学习思路
学习它的“来历”“自身的特点”“适合解决的问题”以及“实际的应用场景"

掌握理论，动手编写，适度刷题，勤思考、多交流，反复迭代沉积。


#### 2. 复杂度分析
##### 2.1 概述
数据结构与算法本质上解决“快”和“省”的问题，即如何更快的运行代码、如何更节省存储空间。可用时间、空间复杂度来分析衡量。

时间、空间复杂度分析是从宏观角度去大体粗略估计程序的时间、空间消耗，和实际跑代码测试观察具体资源消耗是两种不同的思路。实际测试在不同的平台、环境下可能会有着不同的结果。

时间、空间复杂度分析也并不是说就完全准确的评估程序资源消耗，好比如开车从广州到北京，估算下大概需要的时间，那么就会根据正常开车来说大概速度，然后根据距离除以速度，再考虑下中间休息时间，那么就能得出一个大致的时间，但是你说实际路上跑的时候我就慢吞吞的开，那这种算是特殊情况，任何的估算都是一种近似推测。

当然时间、空间复杂度分析肯定不能直接替代实际的测试，我们在评估出相应的复杂度是为了优化代码，但是最终的效果如何，肯定还需要实际的测试，以达到两者结合来反馈实际效率的目的。

##### 2.2 大O复杂度表示法

######  1）时间复杂度

时间复杂度就是来衡量估算代码片段的执行时间，代码块由一行行的代码组成，总体的执行时间必然等于每行代码的执行时间之和，每行代码的执行时间尽管是不一样的，不过我们从整体估算的角度，代码整体执行次数越多那么执行时间也就越长，即 `总体执行时间 = 每行执行时间之和 = 代码行执行次数 * 每次执行平均时间`。

如果每次执行平均时间认为是近似的，其实总体执行时间必然和代码执行执行次数成正比例关系，注意这里不是说和代码行数成比例关系，而是代码行总的执行次数，例如有些代码行数看起来多，有100行，但是没有任何循环，每行执行一次；而有的代码就3行，但是是个循环，执行1万次，那么显然很大概率循环这个代码段执行时间长。
所以我们估算时间复杂度只需要看代码块执行次数即可。

如果用公式表示：`T(n)= O(f(n))`
其中 T(n) 表示代码执行时间；n 代表数据规模大小，不同大小的数据规模所消耗的执行时间肯定是不同的，n越大，则T(n)必然越大；f(n)代表代码执行次数总和，其实也就是每行代码执行次数总和；而大O正是表示总体时间与执行总次数的关系函数，即正比关系：f(n)越大，T(n)越大。

大O表示代码执行时间随数据规模增长的变化趋势，表示的是一种外在函数关系，但是具体说是啥函数关系，是 T(n)= 2 * f(n) 还是说 T(n) = f(n) + 10 呢，这个取决于不同的具体代码段，但是可以肯定的是一定是正比关系。

在分析时间复杂度过程中，可以忽略常数、低阶、系数，记录最大阶的量级即可。例如函数 
```math
T(n)=2n^{2} + 3n + 100
```
这个里面随着n的增大，那么整体的函数变化趋势主要就取决于n平方这个量级了，所以我们可以近似表示为： 
```math
T(n)=n^{2}
```
这个其实就是时间复杂度的一个量级表示。

######  2）复杂度分析方法
a. 关注循环次数最多的部分

在一个代码段中，其他部分几乎都是运算几次的程序，但是存在一个乃至多个循环，那么自然代码段的整体运行时间大概率取决于循环片段代码的执行次数，例如：

```
 int cal(int n) {
   int sum = 0;
   int i = 1;
   for (; i <= n; ++i) {
     sum = sum + i;
   }
   return sum;
 }
```

循环之前代码行执行两次，循环部分执行 2n次（忽略每行实际多次，即一行执行一次的话就是1），那么整体其实取决于循环部分，则整体时间复杂度为  T(n) = O(n) 

b. 加法法则：总的复杂度取决于量级最大的代码复杂度

如果存在多个循环呢？例如：

```
int cal(int n) {
   int sum_1 = 0;
   int p = 1;
   for (; p < 100; ++p) {
     sum_1 = sum_1 + p;
   }
 
   int sum_3 = 0;
   int i = 1;
   int j = 1;
   for (; i <= n; ++i) {
     j = 1; 
     for (; j <= n; ++j) {
       sum_3 = sum_3 +  i * j;
     }
   }
 
   return sum_1 + sum_3;
 }
```

除去常量级运算，包含两个循环一个循环n次，一个循环n方次，那么总体时间复杂度其实可表示为：
```math
T(n)=n + n^{2}
```
这里面明显n方的量级要大于n，当n很大的时候，消耗时间主要取决于n方，可以忽略n，所以该段代码时间复杂度就是：T(n)=n^2

c. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

如果一个循环代码片段执行n次，但是循环内部又调用其他函数，其他函数每次执行m次，那么总体的时间复杂度其实就是两者的乘积，例如：

```
int cal(int n) {
   for (; i < n; ++i) {
     ret = ret + f(i);
   } 
 } 
 
 int f(int m) {
  for (; i < m; ++i) {
    sum = sum + i;
  } 
  return sum;
 }
```

那么整体时间复杂度即：
`T(n) = O(f(n)) * O(f(m)) = O(n) * O(m) = O(n * m)`

